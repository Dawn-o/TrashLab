# -*- coding: utf-8 -*-
"""trashlab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Mz-wgJ0meGMBAgyEUyf_NEVyVeNi6qnX

# **Klasifikasi Gambar Sampah organik dan anorganik**


## **Sumber Dataset**
https://www.kaggle.com/datasets/techsash/waste-classification-data

## Import Semua Packages/Library yang Digunakan
"""

import os, shutil
import zipfile
import random
from random import sample
import shutil
from shutil import copyfile
import pathlib
from pathlib import Path
import numpy as np
import pandas as pd
from tqdm.notebook import tqdm as tq
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.image import imread
import cv2
from PIL import Image
import skimage
from skimage import io
from skimage.transform import resize
from skimage.transform import rotate, AffineTransform, warp
from skimage import img_as_ubyte
from skimage.exposure import adjust_gamma
from skimage.util import random_noise
import keras
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
import tensorflow as tf
from tensorflow.keras import Model, layers
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.layers import InputLayer, Conv2D, SeparableConv2D, MaxPooling2D, MaxPool2D, Dense, Flatten, Dropout, BatchNormalization, Input
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.applications import ResNet50, MobileNetV2
from tensorflow.keras.applications.densenet import DenseNet121
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard
from tensorflow.keras.layers import GlobalAveragePooling2D
from google.colab import drive
from google.colab import files
import PIL
import albumentations as A
from tensorflow.keras.preprocessing.image import array_to_img
from tensorflow.keras.layers import Reshape
from tensorflow.keras.models import load_model
import tensorflow.lite as tflite
import joblib
import pickle
from collections import Counter

# Mencetak versi TensorFlow yang sedang digunakan
print(tf.__version__)

"""## Data Preparation

### Data Loading
"""

# Upload file kaggle.json
files.upload()

# Hapus dataset lama jika ada
!rm -rf waste_classification_data/ waste-classification-data.zip

# Setup Kaggle API
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset dari Kaggle
!kaggle datasets download -d techsash/waste-classification-data

# Unzip dataset ke dalam folder waste_classification_data
!unzip -q waste-classification-data.zip -d waste_classification_data

# Hapus file zip untuk menghemat penyimpanan
!rm waste-classification-data.zip

# Path dataset utama
dataset_path = "/content/waste_classification_data/DATASET"
train_path = os.path.join(dataset_path, "TRAIN")
test_path = os.path.join(dataset_path, "TEST")

# List kelas dalam dataset
classes = [c for c in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, c))]

print(f"Jumlah kelas yang valid: {len(classes)}")
print(f"Kelas yang tersedia: {classes}")

# Cek jumlah gambar per kelas di TRAIN dan TEST
for split, path in zip(["TRAIN", "TEST"], [train_path, test_path]):
    print(f"\nDataset: {split}")
    for c in classes:
        num_images = len(os.listdir(os.path.join(path, c)))
        print(f"Kelas {c}: {num_images} gambar")

# Cek apakah semua gambar valid di TRAIN dan TEST
for split, path in zip(["TRAIN", "TEST"], [train_path, test_path]):
    print(f"\nMemeriksa gambar di {split}...")
    for c in classes:
        class_path = os.path.join(path, c)
        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            try:
                img = Image.open(img_path)
                img.verify()  # Cek validitas gambar
            except Exception as e:
                print(f"Masalah dengan {img_path}: {e}")

def check_images(path, classes):
    print(f"\nMemeriksa gambar di {path}...")
    for c in classes:
        class_path = os.path.join(path, c)
        for img_name in os.listdir(class_path):
            img_path = os.path.join(class_path, img_name)
            try:
                img = Image.open(img_path)
                img.verify()  # Cek file corrupt
                img = Image.open(img_path).convert("RGB")  # Pastikan bisa dibaca ulang
                img.resize((224, 224))  # Resize untuk simulasi preprosesing
            except Exception as e:
                print(f"âŒ Masalah dengan {img_path}: {e}")

check_images(train_path, classes)
check_images(test_path, classes)

# Cek distribusi data
train_counts = [len(os.listdir(os.path.join(train_path, c))) for c in classes]
test_counts = [len(os.listdir(os.path.join(test_path, c))) for c in classes]

plt.figure(figsize=(8, 4))
plt.bar(classes, train_counts, color='blue', alpha=0.7, label="Train")
plt.bar(classes, test_counts, color='red', alpha=0.7, label="Test")
plt.xlabel("Kelas")
plt.ylabel("Jumlah Gambar")
plt.title("Distribusi Data TRAIN & TEST")
plt.legend()
plt.show()

# Fungsi untuk menampilkan sample gambar dari setiap kelas
def show_sample_images(path, classes, num_samples=5):
    fig, axes = plt.subplots(nrows=len(classes), ncols=num_samples, figsize=(num_samples * 2, len(classes) * 2))

    for i, c in enumerate(classes):
        class_path = os.path.join(path, c)
        sample_images = random.sample(os.listdir(class_path), num_samples)  # Ambil 5 gambar random
        for j, img_name in enumerate(sample_images):
            img_path = os.path.join(class_path, img_name)
            img = Image.open(img_path)
            axes[i, j].imshow(img)
            axes[i, j].axis("off")
            axes[i, j].set_title(f"{c} - {img_name[:10]}")

    plt.suptitle("Contoh Gambar dari Setiap Kelas", fontsize=14)
    plt.show()

# Tampilkan sample gambar dari TRAIN set
show_sample_images(train_path, classes, num_samples=5)

"""### Data Preprocessing

#### Split Dataset
"""

# Path dataset utama
dataset_path = "/content/waste_classification_data/DATASET"
train_source_path = os.path.join(dataset_path, "TRAIN")
test_source_path = os.path.join(dataset_path, "TEST")

# Path dataset baru
train_path = "/content/dataset/train"
val_path = "/content/dataset/val"
test_path = "/content/dataset/test"

# Buat folder train, val, test
for path in [train_path, val_path, test_path]:
    os.makedirs(path, exist_ok=True)

# Fungsi preprocessing dengan OpenCV
def preprocess_image(image_path):
    img = cv2.imread(image_path)
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Grayscale

    # Gaussian Blur untuk stabilisasi
    img_blur = cv2.GaussianBlur(img_gray, (5, 5), 0)

    # Canny Edge Detection
    edges = cv2.Canny(img_blur, 50, 150)

    # Watershed segmentation
    ret, thresh = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    kernel = np.ones((3, 3), np.uint8)
    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
    sure_bg = cv2.dilate(opening, kernel, iterations=3)
    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
    ret, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)
    sure_fg = np.uint8(sure_fg)
    unknown = cv2.subtract(sure_bg, sure_fg)

    # Label markers
    ret, markers = cv2.connectedComponents(sure_fg)
    markers = markers + 1
    markers[unknown == 255] = 0
    markers = cv2.watershed(img, markers)
    img[markers == -1] = [255, 0, 0]  # Warna merah untuk boundary

    return img

# Split dataset dari TRAIN
for category in os.listdir(train_source_path):
    class_path = os.path.join(train_source_path, category)

    if os.path.isdir(class_path):
        images = os.listdir(class_path)

        if len(images) > 1:
            # **Perbaikan split: Train 80%, Val 10%, Test 10%**
            train_images, temp_images = train_test_split(images, test_size=0.20, random_state=42)
            val_images, test_images = train_test_split(temp_images, test_size=0.50, random_state=42)
        else:
            train_images, val_images, test_images = images, [], []

        # Buat folder per kelas
        for path in [train_path, val_path, test_path]:
            os.makedirs(os.path.join(path, category), exist_ok=True)

        # Pindahkan gambar ke folder masing-masing
        for img in train_images:
            img_path = os.path.join(class_path, img)
            cv2.imwrite(os.path.join(train_path, category, img), cv2.imread(img_path))
        for img in val_images:
            img_path = os.path.join(class_path, img)
            cv2.imwrite(os.path.join(val_path, category, img), cv2.imread(img_path))
        for img in test_images:
            img_path = os.path.join(class_path, img)
            cv2.imwrite(os.path.join(test_path, category, img), cv2.imread(img_path))

print("âœ… Dataset berhasil diproses! Train: 80%, Val: 10%, Test: 10%.")

# Path dataset setelah split
train_path = "/content/dataset/train"

# Kategori yang lebih jelas
categories = {"O": "Organik", "R": "Anorganik"}

fig, axes = plt.subplots(2, 5, figsize=(12, 6))

for i, (short_label, full_label) in enumerate(categories.items()):
    class_path = os.path.join(train_path, short_label)

    # Cek jika folder ada
    if not os.path.exists(class_path):
        print(f"Folder {class_path} tidak ditemukan!")
        continue  # Skip kalau folder tidak ada

    images = os.listdir(class_path)
    selected_images = random.sample(images, min(5, len(images)))  # Ambil max 5 gambar, kalau kurang ya ambil yang ada

    for j, img_name in enumerate(selected_images):
        img_path = os.path.join(class_path, img_name)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (224, 224))  # Resize biar konsisten

        axes[i, j].imshow(img)
        axes[i, j].axis("off")
        axes[i, j].set_title(f"{full_label} - {img_name}", fontsize=8)

plt.suptitle("Contoh Gambar dari Kelas Organik & Anorganik", fontsize=12)
plt.tight_layout()
plt.show()

"""#### Augmentasi"""

#########################################
# 1. Augmentasi Manual
#########################################
# Path Dataset
original_path = "/content/dataset/train/"  # Gunakan dataset train untuk augmentasi
augmented_path = "/content/dataset/train_augmented/"  # Simpan hasil augmentasi di sini

os.makedirs(augmented_path, exist_ok=True)

# Fungsi Augmentasi Manual
def blur_image(img):
    return cv2.GaussianBlur(img, (5, 5), 0)

def rotate_random(img):
    angle = random.choice([cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_180, cv2.ROTATE_90_COUNTERCLOCKWISE])
    return cv2.rotate(img, angle)

def warp_shift(img):
    rows, cols, _ = img.shape
    src_points = np.float32([[0, 0], [cols, 0], [0, rows]])
    dst_points = np.float32([[cols * 0.1, rows * 0.2], [cols * 0.9, 0], [cols * 0.2, rows]])
    M = cv2.getAffineTransform(src_points, dst_points)
    return cv2.warpAffine(img, M, (cols, rows))

# Proses Augmentasi & Simpan
for class_folder in os.listdir(original_path):  # Loop untuk setiap kelas
    class_path = os.path.join(original_path, class_folder)
    if not os.path.isdir(class_path):
        continue

    # Buat folder di augmented_path untuk kelas ini
    class_aug_path = os.path.join(augmented_path, class_folder)
    os.makedirs(class_aug_path, exist_ok=True)

    for img_name in os.listdir(class_path):
        img_path = os.path.join(class_path, img_name)
        img = cv2.imread(img_path)
        if img is None:
            print(f"File {img_path} tidak bisa dibaca, dilewati.")
            continue

        # Terapkan augmentasi
        augmented_images = [
            blur_image(img),
            rotate_random(img),
            warp_shift(img)
        ]
        # Simpan hasil augmentasi
        for i, aug_img in enumerate(augmented_images):
            aug_img_path = os.path.join(class_aug_path, f"{img_name.split('.')[0]}_aug_{i}.jpg")
            cv2.imwrite(aug_img_path, img_as_ubyte(aug_img))

print("Proses augmentasi selesai!")

"""## ImageDataGenerator"""

#########################################
# 2. Data Generator Setup (untuk training, validasi, test)
#########################################
# Path dataset yang sudah dipisah
TRAIN_DIR = "/content/dataset/train/"
VALID_DIR = "/content/dataset/val/"
TEST_DIR = "/content/dataset/test/"

# Data Augmentation untuk training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Validasi & Test hanya normalisasi
valid_test_datagen = ImageDataGenerator(rescale=1./255)

# Train Generator
train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    batch_size=32,
    target_size=(224, 224),
    color_mode="rgb",
    class_mode='binary',
    shuffle=True
)

# Validation Generator
validation_generator = valid_test_datagen.flow_from_directory(
    VALID_DIR,
    batch_size=32,
    target_size=(224, 224),
    color_mode="rgb",
    class_mode='binary',
    shuffle=False
)

# Test Generator
test_generator = valid_test_datagen.flow_from_directory(
    TEST_DIR,
    batch_size=1,
    target_size=(224, 224),
    color_mode="rgb",
    class_mode='binary',
    shuffle=False
)

print("Total gambar di Training set:", train_generator.samples)
print("Total gambar di Validation set:", validation_generator.samples)
print("Total gambar di Test set:", test_generator.samples)
print("Data preprocessing selesai! Siap ke tahap training ðŸš€")

"""## Modelling"""

# Setup Callback
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, mode='min', verbose=1)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, mode='min', min_lr=1e-6, verbose=1)
model_checkpoint = ModelCheckpoint("best_model.h5", monitor="val_loss", save_best_only=True, mode='min', verbose=1)

# Callback untuk TensorBoard (opsional)
log_dir = "logs"
tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)

# Gabungkan semua callback
callbacks = [early_stopping, reduce_lr, model_checkpoint, tensorboard_callback]

#########################################
# 3. Build & Compile Model
#########################################
# Load MobileNetV2 tanpa fully connected layer terakhir
base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Freeze base model untuk fase awal

# Tambahkan custom head
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = BatchNormalization()(x)
x = Dropout(0.3)(x)
x = Dense(128, activation="relu")(x)
x = Dropout(0.2)(x)
output = Dense(1, activation="sigmoid")(x)

model = Model(inputs=base_model.input, outputs=output)
model.compile(optimizer=Adam(learning_rate=0.0001),
              loss="binary_crossentropy",
              metrics=["accuracy"])

model.summary()

# Hitung jumlah gambar per kelas
count_organik = len(os.listdir(os.path.join(TRAIN_DIR, "O")))
count_anorganik = len(os.listdir(os.path.join(TRAIN_DIR, "R")))

# Hitung class weights
weight_organik = (1 / count_organik) * (count_organik + count_anorganik) / 2.0
weight_anorganik = (1 / count_anorganik) * (count_anorganik + count_organik) / 2.0
class_weights = {0: weight_organik, 1: weight_anorganik}
print(class_weights)

history = model.fit(
    train_generator,
    epochs=15,
    validation_data=validation_generator,
    class_weight=class_weights,  # Gunakan class weights
    callbacks=callbacks
)

# Muat model yang sudah disimpan sebelumnya
model = tf.keras.models.load_model("best_model.h5")

# Bungkus model dengan class agar bisa disimpan dalam Pickle/Joblib
class KerasModelWrapper:
    def __init__(self, model):
        self.model = model

    def predict(self, X):
        return self.model.predict(X)

# Simpan ke Pickle
wrapped_model = KerasModelWrapper(model)
joblib.dump(wrapped_model, "model.pkl")
print("Model disimpan sebagai model.pkl menggunakan Joblib.")

"""## Evaluasi dan Visualisasi"""

# Pastikan test_generator sudah di-reset
test_generator.reset()

# Lakukan prediksi pada test set
predictions = model.predict(test_generator, verbose=1)

# Karena model binary, kita gunakan threshold 0.5
predicted_labels = (predictions > 0.5).astype(int).reshape(-1)
true_labels = test_generator.classes

# Tampilkan classification report
target_names = ['Sampah Anorganik', 'Sampah Organik']
print("Classification Report:\n")
print(classification_report(true_labels, predicted_labels, target_names=target_names, digits=4))

# Buat confusion matrix
cm = confusion_matrix(true_labels, predicted_labels)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=target_names, yticklabels=target_names)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

# Visualisasi grafik training (akurasi & loss)
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(acc) + 1)

plt.figure(figsize=(12, 5))
# Plot akurasi training dan validasi
plt.subplot(1, 2, 1)
plt.plot(epochs, acc, 'bo-', label='Training Accuracy')
plt.plot(epochs, val_acc, 'ro-', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Plot loss training dan validasi
plt.subplot(1, 2, 2)
plt.plot(epochs, loss, 'bo-', label='Training Loss')
plt.plot(epochs, val_loss, 'ro-', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

"""## Konversi Model

#### SavedModel
"""

# Gunakan model.export() untuk menyimpan model dalam format SavedModel
model.export("saved_model_trashlab")
print("Model berhasil disimpan sebagai SavedModel di 'saved_model_trashlab'.")

"""## Inference"""

# Di Keras 3, untuk memuat SavedModel sebagai inference-only layer, gunakan TFSMLayer:
loaded_model = tf.keras.layers.TFSMLayer("saved_model_trashlab", call_endpoint="serving_default")
print("Model berhasil dimuat untuk inference.")

# Fungsi preprocessing gambar
def preprocess_image(image_path):
    img = cv2.imread(image_path)  # Baca gambar
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Konversi ke RGB
    img = cv2.resize(img, (224, 224))  # Sesuaikan ukuran dengan model
    img = img / 255.0  # Normalisasi ke range [0,1]
    img = np.expand_dims(img, axis=0).astype(np.float32)  # Pastikan dimensi sesuai
    return img

# Fungsi Prediksi
def predict_savedmodel(image_path):
    img = preprocess_image(image_path)
    prediction = loaded_model(img)

    # Jika output berbentuk dictionary, ambil key yang benar
    if isinstance(prediction, dict):
        prediction = list(prediction.values())[0]

    # Jika output berbentuk tensor, konversi ke numpy
    if isinstance(prediction, tf.Tensor):
        prediction = prediction.numpy()

    print("Output Model:", prediction)  # Debugging

    # **Mapping sesuai class_indices**
    label = "Organik" if prediction[0][0] < 0.5 else "Anorganik"
    confidence = 1 - prediction[0][0] if label == "Organik" else prediction[0][0]

    return label, confidence


# Contoh penggunaan
image_path = "/content/1.jpg"
label, confidence = predict_savedmodel(image_path)
print(f"Prediksi: {label} (Confidence: {confidence:.2f})")

print(train_generator.class_indices)